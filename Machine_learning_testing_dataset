setwd("E:\\Rwork")
library(RColorBrewer)
library(MASS)
library(C50)
library(ROCR)
#绑定数据集，便于操作
DT_data <- read.csv("GSE32894_for_ML.csv",header = T)
DT_data[is.na(DT_data)] <- 0
DT_data <- DT_data[,-1]
set.seed(1234)
#60% data for train and 40% data for test
index <- sample(nrow(DT_data),0.6*nrow(DT_data))
DT_train <- DT_data[index,]
DT_test <- DT_data[-index,]

DT_train$subtype <- as.character(DT_train$subtype)
DT_train$subtype <- as.factor(DT_train$subtype)
DT_test$subtype <- as.character(DT_test$subtype)
DT_test$subtype <- as.factor(DT_test$subtype)

# ========================================================
#   
# ========================================================
#C5.0决策树分析

set.seed(1234)
tc <- C5.0Control(subset =F,
                  CF=0.25,
                  winnow=F,
                  noGlobalPruning=F,
                  minCases =20)

#subset =F,C5.0命令行版本将此参数默认为FALSE，这意味着在树生长阶段不会尝试尝试分组
# #C50的参数设定，CF为置信因子0.25，代表置信区间为75%；
# winnow为F代表不剔除对目标标量影响较小的变量；
# noGlobalPruning=F代表不使用后剪枝；
# minCases =20代表节点的观测值最小为20，低于20则不构成一个节点
#C5.0函数进行建模，rules=F代表不输出决策树规则
set.seed(1234)
mR_DT <- C5.0( subtype ~.,
               data    = DT_train,
               rules   = F,
               control = tc)
summary(mR_DT) 

# ========================================================
#   
# ========================================================

pred1 <- predict(mR_DT, DT_test)
Freq1 <- table(pred1,DT_test$subtype)
sum (diag(Freq1)) / sum(Freq1)



library(ROCR)
DT_testp <- predict(mR_DT,DT_test,type='prob')[,2]
DT_pred<-prediction(DT_testp,DT_test$subtype)
DT_perf <- performance(DT_pred,"tpr","fpr")

plot(DT_perf, col='blue',lty=2)
auc <- performance(DT_pred,'auc')

# AUC = unlist(auc@y.values)
auc = unlist(slot(auc,"y.values"))

plot(DT_perf,
     xlim=c(0,1), ylim=c(0,1),col='red', 
     main=paste("ROC curve (", "AUC For DT = ",auc,")"),
     lwd = 2, cex.main=1.3, cex.lab=1.2, cex.axis=1.2, font=1.2)
abline(0,1)






setwd("E:\\Rwork")
library(randomForest)
rf_data <- DT_data

set.seed(1234)
#60% data for train and 40% data for test
index <- sample(nrow(rf_data),0.6*nrow(rf_data))
rf_train <- rf_data[index,]
rf_test <- rf_data[-index,]

rf_train$subtype <- as.character(rf_train$subtype)
rf_train$subtype <- as.factor(rf_train$subtype)

rf_test$subtype <- as.character(rf_test$subtype)
rf_test$subtype <- as.factor(rf_test$subtype)

#============================================================

#===========================================================
#-------------find the best mtry value---------------------

n <- 25
set.seed(1234)
library(tcltk)
pb<-tkProgressBar("进度","已完成 %",0,2500) 
for (i in 1:(n)){
  info<- sprintf("已完成 %d%%", round(i*10/length(n)))  
  setTkProgressBar(pb, i*100/length(n), sprintf("进度 (%s)", info),info)
  mtry_fit <- randomForest(subtype~.,data = rf_train,mtry = i)
  rf_testp <- predict(mtry_fit,rf_test,type='prob')[,2]
  rf_pred<-prediction(rf_testp,rf_test$subtype)
  rf_perf <- performance(rf_pred,"tpr","fpr")
  auc <- performance(rf_pred,'auc')
  auc = unlist(slot(auc,"y.values"))
  print(auc )
}
# 
# ===========================================================================
#求最佳mtry
RF_mtry <- read.csv("GSE32894.mtry.csv")
library(ggplot2)
library(RColorBrewer)
library(ggsci)
pdf(file="GSE32894.RF.mtry.pdf",height = 8, width = 8)
par(oma=c(2,2,1,2),mar=c(5,4,4,2))
p1 <- ggplot(RF_mtry , aes(x=mtry, y=AUC))+
  geom_point(size = 3.8,shape=1,color='#7AA6DC',stroke =1.2)

p1 <- p1 +coord_cartesian(ylim=c(0.925, 0.990))
scale_y_continuous(breaks=seq(0.925, 0.990, 0.01)) 

p1 <- p1+scale_x_continuous(breaks=seq(0, 25, 5))+
  geom_line(color='#7AA6DC', size=1.2)+
  theme_bw() + 
  theme(panel.background = element_rect(colour = "black", 
                                        size = 1.5))+
  theme(panel.grid.major  = element_line( size=0.1)) +
  theme(panel.grid.minor = element_blank())+ 
  geom_vline(aes(xintercept=24), 
             colour="#990000",
             linetype="dashed")
p1 <- p1 + theme(axis.text.x = element_text(size = 16,  
                                            vjust = 0.5, 
                                            hjust = 0.5 ))+
  theme(axis.text.y = element_text(size = 16,  
                                   vjust = 0.5, 
                                   hjust = 0.5))+
  theme(axis.text.y.right = element_text(size = 16,  
                                         vjust = 0.5, 
                                         hjust = 0.5))



p1 <- p1 + xlab("mtry Number") + 
  theme(axis.title.x = element_text(size = 16,
                                    
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))+
  
  ylab("AUC")+
  theme(axis.title.y = element_text(size = 16,
                                    
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))


p1
dev.off()








#================================================================


#=================================================================
#--------------find the best number of ntree---------------------



set.seed(1234)

ntree_fit <- randomForest(subtype~.,
                        data=rf_train,
                        mtry=24,
                        ntree=1000)

plot(ntree_fit)


# ==============================================================
#求最佳ntree
m = round(sqrt(dim(rf_train)[2]-1))
m = 24# sqrt(p) rounded to integer
for (i in c(100,200,300,400,500,600,700,800)){ # try three different values for number of trees
  for (j in c(m-2,m-1, m, m+1,m+2)){ # tree three different values for number of predictors to sample
    set.seed(123)
    rf=randomForest(subtype ~., data=rf_train,  
                    mtry=j, ntree=i)
    # get oob error rate for training data
    # yhat=rf$predicted
    # y=rf_train$subtype
    error_rate <- rf$err.rate[i]
    if (exists('oob_err')==FALSE){
      oob_err = c(i,j,error_rate) # create initial data frame
    }
    else{
      oob_err = rbind(oob_err, c(i,j,error_rate)) # append to data frame of error rates, ntree, and mtry
    }
  }
}
oob_err <- as.data.frame(oob_err) # convert to data frame
names(oob_err) <- c('ntree', 'mtry', 'oob_error_rate') # add column names
oob_err$mtry <- as.factor(oob_err$mtry) # mtry to factor
library (ggplot2)
oob_err <- oob_err[order(oob_err$mtry),]



library(ggplot2)
library(RColorBrewer)

# save(oob_err,file="mi_rf_oob_err.Rda")
# load("mi_rf_oob_err.Rda")
# setwd("E:\\Rwork\\ML.pic")
set1 <- c(brewer.pal(5,"Set1"))



pdf(file="GSE32894.RF.ntree.pdf",height = 8, width = 8)
par(oma=c(2,2,1,2),mar=c(5,4,4,2))
p1 <- ggplot(oob_err, aes(x=ntree, y=oob_error_rate, color=mtry))+
  geom_point(size=3.8,shape=1,stroke =1.2)+
  geom_line(size=2)+scale_color_manual(breaks = c("22", "23","24",
                                                  "25", "26"),
                                       values=set1) +
  theme_bw() + 
  theme(panel.background = element_rect(colour = "black", 
                                        size = 1.5))+
  theme(panel.grid.major  = element_line( size=0.1)) +
  theme(panel.grid.minor = element_blank())

p1 <- p1 + theme(legend.title   = element_text(size = 16, face = "bold"))+
  theme(legend.background   = element_rect(fill = "white"))+
  theme(legend.text = element_text(size = 14))+
  theme(legend.position = "right")



p1 <- p1 +coord_cartesian(ylim=c(0.1, 0.25))


p1 <- p1 + theme(axis.text.x = element_text(size = 16,  
                                            vjust = 0.5, 
                                            hjust = 0.5 
))+
  theme(axis.text.y = element_text(size = 16,  
                                   vjust = 0.5, 
                                   hjust = 0.5))+
  theme(axis.text.y.right = element_text(size = 16,  
                                         vjust = 0.5, 
                                         hjust = 0.5))



p1 <- p1 + xlab("TreeNumber") + 
  theme(axis.title.x = element_text(size = 16,
                                    
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))+
  
  ylab("Oob Error Rate")+
  theme(axis.title.y = element_text(size = 16,
                                    
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))

p1 
dev.off()




#==========================================================
#交叉检验
data <- rf_train
library("caret")  
set.seed(1234)
folds<-createFolds(y=data$subtype,k=10) 
re <- {}
for(i in 1:10){  
  traindata <- data[-folds[[i]],]  
  testdata <- data[folds[[i]],]  
  rf <- randomForest(subtype ~ ., data=traindata, 
                     ntree=200, proximity=TRUE,
                     mtry = 5) 
  
  pred1 <- predict(rf,testdata)
  Freq1 <- table(pred1,testdata$subtype)
  temp<- sum(diag(Freq1))/sum(Freq1)
  re <- c(re,temp)
}  
re <- as.data.frame(re)
re$K.fold  <- row.names(re)
names(re)[1] <- c("ACC")
library (ggplot2)
rf_Kfold <- re
mean(rf_Kfold$ACC)
fix( rf_Kfold)



library(RColorBrewer)
set1 <- c(brewer.pal(5,"Set1"))
pdf(file="GSE32894.RF.Kfold.pdf",height = 8, width = 8)
par(oma=c(2,2,1,2),mar=c(5,4,4,2))
rf_Kfold$K.fold <- as.numeric(rf_Kfold$K.fold)





rf_Kfold$pos <- rf_Kfold$K.fold == 11 
rf_Kfold$pos  <- as.factor(rf_Kfold$pos)
rf_Kfold$ACC   <- as.numeric(rf_Kfold$ACC)
rf_Kfold$ACC <- round(rf_Kfold$ACC,2)



p1 <- ggplot(rf_Kfold, aes(x=K.fold, y=ACC))+
  geom_bar(aes(fill=pos),stat = "identity", width = 0.8)+
  scale_fill_manual(values=set1[2:1])
p1 <- p1 +  coord_cartesian(ylim=c(0.7, 1))+
  scale_y_continuous(breaks=seq(0.70, 1, 0.07)) +
  scale_x_continuous(breaks = seq(1,11,1))+
  geom_text(aes(label = ACC), vjust = 1.5, 
            colour = "black", position = position_dodge(.9), 
            size = 5)+
  theme_bw() + 
  theme(panel.background = element_rect(colour = "black", 
                                        size = 1.5))+
  theme(panel.grid.major  = element_line( size=0.1)) +
  theme(panel.grid.minor = element_blank())

p1 <- p1 + theme(axis.text.x = element_text(size = 16,  
                                            vjust = 0.5, 
                                            hjust = 0.5))+
  theme(axis.text.y = element_text(size = 16,  
                                   vjust = 0.5, 
                                   hjust = 0.5))+
  theme(axis.text.y.right = element_text(size = 16,  
                                         vjust = 0.5, 
                                         hjust = 0.5))



p1 <- p1 + xlab("KFold Number") + 
  theme(axis.title.x = element_text(size = 16,
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))+
  
  ylab("Accuracy")+
  theme(axis.title.y = element_text(size = 16,
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))

p1 <- p1 + theme(legend.title = element_text(size = 16, face = "bold"))+
  theme(legend.background   = element_rect(fill = "white"))+
  
  theme(legend.text = element_text(size = 14))+
  guides(fill=FALSE)
p1 
dev.off()


#======================================================================

#======================================================================
#---------------------establish the model-------------------------------

set.seed(1234)
system.time (rf <- randomForest(subtype~.,
                   data = rf_train ,
                   mtry = 24,
                   ntree = 400,
                   importance= TRUE,
                   proximity = TRUE))
rf

#==========================================================================


#=========================================================================
#--------------evaluate the error of testing group------------------------


pred1 <- predict(rf,rf_test)
Freq1 <- table(pred1,rf_test$subtype)
sum (diag(table(predict(rf,rf_test),rf_test$subtype))) / sum(Freq1)

#==========================================================================

===========================================================
  #-------- calculate AUC : method 1-------------------------

library(ROCR)
rf_testp <- predict(rf,rf_test,type='prob')[,2]
rf_pred<-prediction(rf_testp,rf_test$subtype)
rf_perf <- performance(rf_pred,"tpr","fpr")

plot(rf_perf, col='blue',lty=2)
auc <- performance(rf_pred,'auc')

# AUC = unlist(auc@y.values)
auc = unlist(slot(auc,"y.values"))

plot(rf_perf,
     xlim=c(0,1), ylim=c(0,1),col='red', 
     main=paste("ROC curve (", "AUC For RF = ",auc,")"),
     lwd = 2, cex.main=1.3, cex.lab=1.2, cex.axis=1.2, font=1.2)
abline(0,1)






                           
             
library(mlbench)
library(caret)
                               
setwd("E:\\Rwork")
                               
mydata <- DT_data
mydata$subtype <- as.numeric(mydata$subtype)
mydata$subtype <- mydata$subtype - 1
# Set the seed to create reproducible train and test sets
set.seed(1234)
# Create a stratified random sample to create train and test sets
# Reference the outcome variable
trainIndex   <- createDataPartition(mydata$subtype, 
                                    p=0.6,
                                    list=FALSE, 
                                      times=1)
                               
train   <- mydata[trainIndex,]
test    <- mydata[-trainIndex,]
# Create separate vectors of our outcome variable for both our train and test sets
# We'll use these to train and test our model later
train.label  <- train$subtype
test.label   <- test$subtype
                               
# Load the Matrix package
library(Matrix)
                               
# Create sparse matrixes and perform One-Hot Encoding to create dummy variables
dtrain  <- sparse.model.matrix(subtype ~ .-1, data=train)
dtest   <- sparse.model.matrix(subtype ~ .-1, data=test)
                               
# View the number of rows and features of each set
dim(dtrain)
dim(dtest)
                               
# Load the XGBoost package
library(xgboost)
                               
# Set our hyperparameters
param <- list(objective   = "binary:logistic",
                                             eval_metric = "auc",
                                             max_depth   = 14,
                                             eta         = 0.001,
                                             gammma      = 1,
                                             colsample_bytree = 0.6,
                                             min_child_weight = 1,
                                             seed = 234)
                               
                               
cv.res = xgb.cv(data = dtrain, nfold = 10,
                nrounds = 2500,
                label   = train.label, 
                objective = "binary:logistic",
                eval_metric = "error",
                eta         = 0.001, max_depth   = 14,
                gammma      = 1,
                colsample_bytree = 0.6,print_every_n=100,
                min_child_weight = 1,
                seed = 1234)   

# Pass in our hyperparameteres and train the model 
system.time(xgb <- xgboost(params  = param,
                           data    = dtrain,
                           label   = train.label, 
                           nrounds = 1201,
                           print_every_n = 100,
                           verbose = 1))
 
 
 
                               
#----------------------------------------------------------------------
# Create our prediction probabilities
pred_xg <- predict(xgb, dtest)                           
library(ROCR)
# Use ROCR package to plot ROC Curve
xgb.pred <- prediction(pred_xg, test.label)
xgb.perf <- performance(xgb.pred, "tpr", "fpr")
plot(xgb.perf, col='blue',lty=2)
auc <- performance(xgb.pred,'auc')
auc = unlist(slot(auc,"y.values"))
plot(xgb.perf,
      xlim=c(0,1), ylim=c(0,1),col='red', 
      main=paste("ROC curve (", "AUC = ",auc,")"),
      lwd = 2, cex.main=1.3, cex.lab=1.2, cex.axis=1.2, font=1.2)
abline(0,1)
                            
 
 
 
 
#----------------------------------------------------------------------
set1 = c(brewer.pal(9,"Set1"), 
         brewer.pal(8, "Dark2"))

pdf(file="GSE32894.pdf")


library(ROCR)
testp_rf <- predict(rf,rf_test,type='prob')[,2]
pred_rf <- prediction(testp_rf,rf_test$subtype)
perf_rf <- performance(pred_rf,"tpr","fpr")

auc_rf <- performance(pred_rf,'auc')
auc_rf = unlist(slot(auc_rf,"y.values"))

plot(perf_rf,
     xlim =c(0,1), ylim=c(0,1),col=set1[1], 
     main = "",
     lwd = 2, 
     cex.main=1.3,
     cex.lab=1.2, 
     cex.axis=1.2,
     font=1.2,
)

graphics::abline(a = 0,  b = 1,lwd = 2,lty=2)

xgb.pred <- prediction(pred_xg, test.label)
xgb.perf <- performance(xgb.pred, "tpr", "fpr")

auc_xg <- performance(xgb.pred,'auc')
auc_xg = unlist(slot(auc_xg,"y.values"))

plot(xgb.perf,col=set1[2],add = TRUE,lwd = 2)
plot(DT_perf, col=set1[9],add = TRUE,lwd = 2)

legend("bottomright", bty = "n" ,
       col=c(set1[1],set1[2], set1[9]), 
       lty=1, c("RandomeForest Auc : 0.974",
                "XGboost Auc : 0.977",
                "DesicionTree Auc : 0.830"),lwd=2)

dev.off()
#----------------------------------------------------------------------
set1 = c(brewer.pal(9,"Set1"),  brewer.pal(8, "Dark2"))
pdf(file="GSE32894.xg.rf.pdf")
library(ROCR)
testp_rf <- predict(rf,rf_test,type='prob')[,2]
pred_rf <- prediction(testp_rf,rf_test$subtype)
perf_rf <- performance(pred_rf,"tpr","fpr")
auc_rf <- performance(pred_rf,'auc')
auc_rf = unlist(slot(auc_rf,"y.values"))
plot(perf_rf, xlim =c(0,1), ylim=c(0,1),col=set1[1], 
                                    main = "",
                                    lwd = 2, 
                                    cex.main=1.3,
                                    cex.lab=1.2, 
                                    cex.axis=1.2,
                                    font=1.2)
graphics::abline(a = 0,  b = 1,lwd = 2,lty=2)
xgb.pred <- prediction(pred_xg, test.label)
xgb.perf <- performance(xgb.pred, "tpr", "fpr")
auc_xg <- performance(xgb.pred,'auc')
auc_xg = unlist(slot(auc_xg,"y.values"))
plot(xgb.perf,col=set1[2],add = TRUE,lwd = 2)

                               
legend("bottomright", bty = "n" ,col=c(set1[1],set1[2], set1[9]), 
         lty=1, c("RandomeForest Auc : 0.974",
                    "XGboost Auc : 0.977"),lwd=2)
dev.off()



set1 <- c(brewer.pal(5,"Set1"))

xg.cv <- read.csv("GSE32894.xg.CV.csv")
library(ggplot2)
library(RColorBrewer)
library(ggsci)
pdf(file="GSE32894.xg.cv.pdf",height = 8, width = 8)
par(oma=c(2,2,1,2),mar=c(5,4,4,2))
xval = xg.cv$IterNumber/100
xg.cv$ACC  =  round(xg.cv$ACC,2)
p1 <- ggplot(xg.cv, aes(x=factor(IterNumber), y=ACC))+
  geom_bar(fill=set1[2],stat = "identity", width = 0.8)

p1 <- p1 + coord_cartesian(ylim=c(0.79, 0.89))+
  scale_y_continuous(breaks=seq(0.79, 0.89, 0.02))+
  geom_text(aes(label = ACC), vjust = 1.5, 
            colour = "black", position = position_dodge(.9), 
            size = 5)+
  theme_bw() + 
  theme(panel.background = element_rect(colour = "black", 
                                        size = 1.5))+
  theme(panel.grid.major  = element_line( size=0.1)) +
  theme(panel.grid.minor = element_blank())

p1 <- p1 + theme(axis.text.x = element_text(size = 16,  
                                            vjust = 0.5, 
                                            hjust = 0.5))+
  theme(axis.text.y = element_text(size = 16,  
                                   vjust = 0.5, 
                                   hjust = 0.5))+
  theme(axis.text.y.right = element_text(size = 16,  
                                         vjust = 0.5, 
                                         hjust = 0.5))



p1 <- p1 + xlab("Iter Number") + 
  theme(axis.title.x = element_text(size = 16,
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))+
  
  ylab("Accuracy")+
  theme(axis.title.y = element_text(size = 16,
                                    face = "bold", 
                                    vjust = 0.5, 
                                    hjust = 0.5))

p1 <- p1 + theme(legend.title = element_text(size = 16, face = "bold"))+
  theme(legend.background   = element_rect(fill = "white"))+
  
  theme(legend.text = element_text(size = 14))+
  guides(fill=FALSE)
p1 
dev.off()
